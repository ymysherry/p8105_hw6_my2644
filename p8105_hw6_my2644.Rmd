---
title: "p8105_hw6_my2644"
author: "ymysherry"
date: "12/9/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(mgcv)
```
## Problem 1


```{r}
homicide_df =
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1
    )
  ) %>%
  filter(
        victim_race %in% c("White", "Black"),
  city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


start with one city



```{r}
baltimore_df= 
    homicide_df %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
     models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, term, OR, starts_with("CI"))
```


```{r}
models_results_df %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Problem 2
tidy the birthweight dataset:
```{r}
bweight_df = 
  read_csv("data/birthweight.csv") %>%
  drop_na() %>%
  janitor::clean_names() %>%
  mutate(babysex = as.factor(babysex),
         malform = as.factor(malform),
         )
```

Fit a model:

 I started by the hypothesis that baby's birth weight is associated with a number of predictors including: baby's sex,presence of malformations that could affect weight (0 = absent, 1 = present), average number of cigarettes smoked per day during pregnancy,gestational age in weeks, mother’s age at delivery (years), mother’s pre-pregnancy BMI. The raw linear model only includes coefficients of main effects.

```{r}
model_fit = lm(bwt ~ babysex + malform + gaweeks + momage + ppbmi, data = bweight_df) %>%
  broom::tidy()
```

At the significance level of 0.05, there are sufficient evidence to conclude that malform is not a significant predictor for baby's birthweight. Therefore   malform is excluded from my raw model. Rerun the model with remaining predictors:

```{r}
model1_fit = lm(bwt ~ babysex + gaweeks + momage + ppbmi, data = bweight_df)
```

The estimated correlation coefficients all have p-value<0.05, indicating all predictors are significant at alpha=0.05. Now create a ggplot of model residuals against fitted-values.

```{r}
bweight_df %>%
  modelr::add_residuals(model1_fit) %>%
  modelr::add_predictions(model1_fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
```

Build the second using length at birth and gestational age as predictors (main effects only).
Build the third model using head circumference, length, sex, and all interactions (including the three-way interaction) between these.

```{r}
model2_fit = lm(bwt ~ blength + gaweeks, data = bweight_df)
model3_fit = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = bweight_df)
```

Compare the 3 models.
use mutate + map & map2 to fit models to training data and obtain corresponding RMSEs for the testing data
```{r}
cv_df = 
  crossv_mc(bweight_df, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    model1_fit  = map(train, ~lm(bwt ~ babysex + gaweeks + momage + ppbmi, data = .x)),
    model2_fit  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model3_fit  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = as_tibble(.x)))) %>% 
  mutate(
    rmse_1 = map2_dbl(model1_fit, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model2_fit, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model3_fit, test, ~rmse(model = .x, data = .y))) %>% 

  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

This plot shows the distribution of prediction error for each model
```{r}
cv_df 
```

It is observed that the RMSE decreases significantly in model 3, which indicates that the accuracy of predictive values increases in model 3. 
Among all of the 3 models, we can conclude that the model 3 using head circumference, length, sex, and all interactions between these produces the most most accurate predicted values.

###Problem 3
Import dataset:
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities: 
- r̂ 2
- log(β̂ 0∗β̂ 1) 

So we need to build a simple linear regression with tmax as the response and tmin as the predictor, and are interested in the distribution of two quantities estimated from these data.

1) 
```{r}
bootstrap_df = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    r_results = map(models, broom::glance),
    coe_results = map(models, broom::tidy)) %>% 
  select(-strap, -models)
```

show plots for r^2 and its 95%CI:
```{r}
r_sqr =
  bootstrap_df %>%
  unnest(r_results) %>%
  select(- coe_results)

r_sqr_plot=
  r_sqr %>%
  ggplot(aes(x = r.squared)) + 
  geom_density()

r_sqr %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975)) %>%
  knitr::kable(digits = 3)
```

The distribution of estimated r-square is normal, and 95% CI of r-squared is (0.894, 0.927).


1). Note: broom::glance() is helpful for extracting r̂ 2 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing log(β̂ 0∗β̂ 1).

Calculate estimated coefficients for log(beta0 * beta1) and its 95% CI.

```{r}
log_est = 
  bootstrap_df %>%
  unnest(coe_results) %>%
  select(- r_results)
  
beta_0 = 
  log_est %>%
  filter(term == "(Intercept)") %>%
  rename(beta0 = estimate) %>%
  select(-term, - p.value, -statistic)

beta_1 = 
  log_est %>%
  filter(term == "tmin") %>%
  rename(beta1 = estimate) %>%
  select(-term, - p.value, -statistic)

beta_df = 
  merge(
    beta_0,
    beta_1,
    by = ".id"
  ) %>%
  mutate(log_beta = log(beta0 * beta1))

log_beta_plot=
    beta_df %>%
  ggplot(aes(x = log_beta)) + 
  geom_density()

beta_df %>% 
  summarize(
    ci_lower = quantile(log_beta, 0.025), 
    ci_upper = quantile(log_beta, 0.975)) %>%
  knitr::kable(digits = 3)
```

The distribution of log(beta0 * beta1) is overall normally distributed but slightly left-skewed, indicating that outliers might be present in the 5000 bootstrap samples. 

The 95% CI of log(beta0 * beta1) is (1.965, 2.060).

